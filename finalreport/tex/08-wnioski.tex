Na podstawie uzyskanych wyników, możemy stwierdzić, że udało nam się stworzyć prosty system, który jest w stanie odpowiadać na pytania zadane w~języku polskim.

Najlepsze rezultaty uzyskaliśmy przy rozpoznawaniu dat, co oznacza, że dobrą decyzją było zastosowanie do tego celu wyrażeń regularnych. Przyzwoicie wypadły także pytania o miejsce, rzecz i osobę. Najgorzej nasz system poradził sobie z rozpoznawaniem wielkości, do których zaliczały się zarówno cechy ilościowe (odpowiadające na pytania \emph{Ile?}), jak i jakościowe (odpowiadające na pytania \emph{Jaki?}). Tak niski procent poprawnych odpowiedzi wynika najprawdopodobniej z tego, że nasz algorytm nie potrafi rozpoznać poprawnie typu oczekiwanej odpowiedzi i być może należałoby zastanowić się nad modyfikacjami w algorytmie. Przykładem na to, że algorytm nie potrafi odpowiednio rozpoznać typu oczekiwanej odpowiedzi jest pytanie \emph{Jaki post obowiązuje w piątek?}. Zgodnie z naszym algorytmem, analizowany jest wyraz \emph{post}. Zamiast tego, algorytm powienien wykryć, że w pytaniu należy określić rodzaj/cechę postu, czyli mięsny.

Korzystanie z zewnętrznych usług z systemu \emph{CLARIN} jak i wyszukiwarek internetowych jest jednocześnie ogromną zaletę jak i wadą naszego systemu. Wśród minusów takiego rozwiązania można wymienić to, że odpowiadanie na pytania działa wyłącznie wtedy, gdy dostępne jest połączenie internetowe oraz działają usługi \emph{CLARIN}. Dwukrotnie zdarzyło nam się, że usługi systemu \emph{CLARIN} przez cały dzień nie były dostępne, co sprawiało, że nasz system nie działał. Dodatkowo korzystanie z tych usług sprawia, że czas potrzebny na zwrócenie odpowiedzi na pytanie znacząco się wydłuża. Kolejną wadą jest też pewne uzależnienie od formy aktualnie zwracanej przez usługę. Zarówno w zewnętrznych usługach systemu \emph{CLARIN}, jak i wyszukiwarkach internetowych mogą zostać wprowadzone zmiany, które sprawią, że format zwracanych przez nie rezultatów zmieni się i nasz system może wtedy przestać poprawnie działać aż do wprowadzenia przez nas aktualizacji. 

Ryzykownym założeniem w naszym systemie jest także ograniczenie się do uni-, bi- i trigramów, co uniemożliwiło odszukanie odpowiedzi na pytanie \emph{Jak nazywali się trzej słynni bracia z legendy?}, ponieważ odpowiedź \emph{Lech, Czech i Rus} zawiera 4 wyrazy. Założyliśmy jednak, że w tak krótkich podsumowaniach prawdopodobieństwo odnalezienia powtarzających się n-gramów o długości większej niż 3 jest niskie.

Problemy występowały także przy określaniu typu oczekiwanej odpowiedzi na podstawie typu pytania. W szczególności nie zawsze wykorzystywane przez nas reguły sprawiały, że typ oczekiwanej odpowiedzi został poprawnie określony. Przykładem na to jest pytanie \emph{Pod jakim pseudonimem pisał Aleksander Głowacki?} Na podstawie rzeczownika \emph{pseudonim} nie da się określić jednoznacznie typu odpowiedzi, ponieważ pseudonimem mogłby być wyraz z domeny MIEJSCE, RZECZ jak i OSOBA.

Problematyczne okazało się także zadanie z pozoru proste, czyli stworzenie całkowicie automatycznego modułu testującego nasze rozwiązanie. O ile zaimplementowany został moduł zadający pytania do naszego systemu i zapisujący odpowiedzi do pliku, to porównanie uzyskanych rezultatów z oczekiwanymi okazało się zbyt skomplikowane. Wynika to między innymi z istnienia więcej niż jednej poprawnej odpowiedzi na dane pytanie. Przykładowo przy pytaniu o wynalazek, który zapoczątkował rewolucję przemysłową, spodziewaliśmy się odpowiedzi \emph{maszyna parowa}. Wyszukiwarka zwróciła jednak odpowiedź \emph{silnik parowa}, którą to także uznaliśmy za poprawną. Podobnie przy pytaniu o polską pisarkę, która otrzymała Nagrodę Nobla, w zależności od wyszukiwarki otrzymywaliśmy odpowiedź Olga Tokarczuk lub Wisława Szymborska. Jeszcze większe problemy napotkaliśmy przy sprawdzaniu poprawności dat, ponieważ pytane \emph{Kiedy rozpoczęła się druga wojna światowa?} nie określa formatu oczekiwanej odpowiedzi, tj. czy poprawne jest zwrócenie jedynie roku czy wymagane jest podanie całej daty. 

\subsection{Perspektywy rozwoju}
Z uwagi na dużą modularność systemu, poszczególne aspekty naszego rozwiązania łatwo poddać ewentualnym przeróbkom. Po przeprowadzeniu testów zgromadziliśmy pewne przemyślenia, które poprawiłyby jakość odpowiedzi zwracanych przez nasz system. 

\subsubsection{Szukanie odpowiedzi w całych dokumentach}
Podsumowania zwracane przez wyszukiwarki nie zawsze zawierają odpowiedź na zadane pytanie. W wielu przypadkach strona, na którą wskazuje podsumowanie rzeczywiście zawiera odpowiedź na dane pytanie, jednak interesujące nas fragmenty nie znajdują się w snippecie zwróconym przez przeglądarkę. Być może dobrym dalszym krokiem w rozwoju naszego systemu byłoby zaprojektowanie kolejnego dużego modułu, który pobierałby całą zawartość dokumentu, analizował go, i zwracał tylko najbardziej istotne fragmenty.

\subsubsection{Zwracanie listy najlepiej ocenionych odpowiedzi}
Jak zauważyliśmy bardzo często poprawne odpowiedzi pojawiały się na listach z n-gramami. Powodem, dla którego nie zostały wybrane było między innymi to, że zostało zwrócone inne, popularniejsze słowo powiązane z daną tematyką. Przykładem na to jest zwrócenie wyrazu \emph{koń} zamiast \emph{cylinder} w pytaniu o rodzaj nakrycia głowy stosowany w dyscyplinie ujeżdżania lub okrągłych rocznic dat wydarzeń, zamiast rzeczywistych dat. Zwrócenie obok odpowiedzi, listy z kilkoma innymi propozycjami zwiększyłoby prawdopodobieństwo otrzymania poprawnej odpowiedzi.

\subsubsection{Przetestowanie innych podejść do rozpoznawania typu potencjalnej odpowiedzi oraz wyszukiwania odpowiedzi}
Zarówno rozpoznawanie typu potencjalnej odpowiedzi jak i wyszukiwania konkretnej odpowiedzi z podsumowań można by wykorzystać sieci neuronowe. Nie zdecydowaliśmy się na to podejście w projekcie z uwagi na to, że chcieliśmy zapoznać się z różnymi, dostępnymi rozwiązaniami dla języka polskiego, m.in. z możliwościami oferowanymi przez \emph{plWordnet} czy usługami z systemu \emph{CLARIN}, ale być może podejście z wykorzystaniem sieci neuronowych osiągałoby lepsze rezultaty.

\subsubsection{Zwiększenie liczby rozpoznawanych domen}
W dalszych krokach można by także powiększyć liczbę rozpoznawanych dziedzin poszerzając listę o kolejne pozycje, albo poprzez uszczegółowienie obecnej. Można by także zrezygnować z własnych domen i przejąć nazewnictwo domen istniejących w narzędziu \emph{plWordnet}. 

\subsubsection{Wykorzystanie innych zewnętrznych usług}
Wykorzystywane przez nas zewnętrzne usługi nie są idealne tj. nie zawierają wszystkich przypadków występujących w języku polskim. Narzędzie \emph{plWordnet} nie ma pełnej bazy wyrazów oraz nie odnajduje wszystkich znaczeń, \emph{Spejd} nie zawsze zwracał poprawny w danej sytuacji leksem i mylił się przy odmianach przez przypadki, zdarzało się także że \emph{Chunker} nieprawidłowo określał granicę wyrazów. Dlatego, aby poprawić jakość zwracanych odpowiedzi, można by zwiększyć ilość zewnętrznych usług, z których korzystamy. W szczególności rozważylibyśmy tu dodanie analizy zależności pomiędzy wyrazami, czyli budowanie drzew rozbioru. Dodatkowo można by wprowadzić pewną redundancję. Funkcjonalność niektórych zewnętrznych usług pokrywa się. Można by zwiększyć prawdopodobieństwo otrzymania prawidłowego w danej sytuacji rezultatu poprzez wprowadzenie mechanizmu głosowania. Przykładowo do wyznaczenia leksemu można by skorzystać z trzech niezależnych usług, aby na koniec przeprowadzić głosowanie w celu wybrania wspólnego, najczęściej pojawiającego się rozwiązania. 

\subsubsection{Rozszerzenie istniejących modułów}
Przy analizie wyników zaobserwowaliśmy, że w naszym systemie są elementy, które można by jeszcze udoskonalić. Jednym z takich aspektów jest uszczegółowienie i rozszerzenie listy sprawdzanych wyrażeń regularnych przy pytaniach o daty i wielkości. Przykładowo można by dodać rozpoznawanie wyrażeń takich jak jednostki, \emph{wiek} czy \emph{przed naszą erą}. Dodatkowo można by się zastanowić nad ujednoliceniem niektórych sformułowań, np. rozpoznawanie \emph{św.} oraz święty jako to samo wyrażenie. Podobny zabieg można by wprowadzić przy datach i liczbach. 

Dodatkowo można by wprowadzić większą liczbę parametrów, w szczególności rozdzielić parametr \emph{minimum\_ngram\_appearance} na osobny dla uni-, bi- i trigramów. Tak samo można by zbadać i oceniać prawdopodobieństwo z jakim dana domena występuje przy danym typie pytania. Przykładowo jak często na pytanie \emph{Gdzie?} odpowiedź będzie dotyczyła miejsca, a jak często rzeczy. Tak samo pewne wagi można by przyporządkować do wyrażeń regularnych, aby faworyzować wyszukiwanie całych dat nad zwracaniem informacji tylko o miesiącu. 

Pewne udoskonalenia można by także wprowadzić w module rozpoznawania typu oczekiwanej odpowiedzi. Obecnie w drugim etapie typ oczekiwanej odpowiedzi określany jest na podstawie analizy pojedynczego wyrazu. Być może w niektórych przypadkach nie będzie to wystarczające i niezbędne okazałoby się przeanalizowanie całej grupy wyrazów znajdujących się za zaimkiem pytającym lub chociażby znalezienie zależności pomiędzy nimi. 

Ostatnim aspektem do rozważenia jest odnalezienie narzędzia, o ile takowe istnieje, które zwróciłoby leksemy uwzględniające zwroty o długości większej niż jeden wyraz. Przykładowo obecnie nasz system ma problem z odpowiedzią na pytanie o maszynę parową, ponieważ odnajdywane są leksemy \emph{maszyna} i \emph{parowy}. Bigram \emph{maszyna parowy} nie zostanie odnaleziony w bazie \emph{plWordnet}. Wyszukanie oryginalnej formy wyrazów również może nie zwrócić poprawnej odpowiedzi, ponieważ narzędzie \emph{plWordnet} dla odmienionego zwrotu (przykładowo \emph{maszyną parową}) również nie zwróci żadnego wyniku.

